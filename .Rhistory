ss <- tokenize(Train_dat[1,10], language = "en")
ss
Train_dat[1,7]
length(ss)
?regexpr
Train_dat[,10] <- apply(Train_dat, 1, function(x) gsub("([[:punct:]]+)","",x[3]))
View(Train_dat)
ss <- tokenize(Train_dat[1,10], language = "en")
length(ss)
Train_dat[1,10]
View(Train_dat)
Train_dat[,7] <- apply(Train_dat, 1, function(x) gsub("([[:punct:]]+)","",x[3]))
names(Train_dat)
View(Train_dat)
names(Train_dat)[7]
names(Train_dat)[7] <- "Essay_Plain_Text"
Train_dat[,8] <- apply(Train_dat, 1, function(x){
mm <- x[3]
if (regexpr("[[:punct:]]+", mm) == 1)
{
mm <- sub("([[:punct:]]+)","",mm)
}
if (regexpr("[[:space:]]+", mm) == 1)
{
mm <- sub("([[:space:]]+)","",mm)
}
nn <- length(gregexpr("\\W+", mm)[[1]])
return (nn)
#return(mm)
})
names(Train_dat)[8] <- c("word_count")
class(Train_dat[,2])
Train_dat[,2] <- factor(Train_dat[,2])
names(Train_dat)
sentence_count <- apply(Train_dat, 1, function(x) length(sentDetect(x[3], language = "en")))
Train_dat <- cbind(Train_dat,sentence_count)
Train_dat$avg_stnce_lgth <- Train_dat[,8]/Train_dat[,9]
View(Train_dat)
ss <- tokenize(Train_dat[,7], language = "en")
Train_dat$word_count2 <- apply(Train_dat, 1, function(x) tokenize(x[7], language = "en"))
ss <- tokenize(Train_dat[1,7], language="en")
ss
length(ss)
nchar(ss, type="chars", allowNA=F)
a1 <- nchar(ss, type="chars", allowNA=F)
a1
sum(a1)
a1 <- sum(nchar(ss, type="chars", allowNA=F))
a1 <- sum(nchar(ss, type="chars", allowNA=F))
nchar(Train_dat[1,7],type="chars", allowNA=F)
?system.time
system.time(sum(nchar(ss, type="chars", allowNA=F)))
system.time(nchar(Train_dat[1,7],type="chars", allowNA=F))
Train_dat$word_count2 <- apply(Train_dat, 1, function(x) length(tokenize(x[7], language = "en")))
View(Train_dat)
Train_dat$total_char <- apply(Train_dat, 1, function(x) nchar(gsub("([[:space:]]+)","",x[7]), type="chars", allowNA=F)
Train_dat$total_char <- apply(Train_dat, 1, function(x) nchar(gsub("([[:space:]]+)","",x[7]), type="chars", allowNA=F))
Train_dat$total_char <- apply(Train_dat, 1, function(x) nchar(gsub("([[:space:]]+)","",x[7]), type="chars", allowNA=F))
View(Train_dat)
Train_dat$avg_word_length <- Train_dat$total_char/Train_dat$word_count2
Train_dat$diff <- Train_dat$word_count-Train_dat$word_count2
Train_dat$diff
View(Train_dat)
a3 <-tagPOS(Train_dat[1,3], language="en")
a3
str_count(a3, c("/JJ", "/JJR", "/JJS"))
require(stringr)
str_count(a3, c("/JJ", "/JJR", "/JJS"))
sum(str_count(a3, c("/JJ", "/JJR", "/JJS")))
adv_count <- sum(str_count(a3, c("/RB", "/RBR", "/RBS")))
adv_count
str_count(a3, c("/RB", "/RBR", "/RBS"))
to_count <- str_count(a3, "/TO")))
to_count <- str_count(a3, "/TO")
to_count
dt_count <- str_count(a3, "/DT")
dt_count
in_count <- str_count(a3, "/IN")
in_count
a3 <-tagPOS(Train_dat[,3], language="en")
a3 <-tagPOS(Train_dat[1:2,3], language="en")
a3
str_count(a3, c("/JJ", "/JJR", "/JJS"))
essay_tagged <-tagPOS(Train_dat[1:10,3], language="en")
adj_count <- sum(str_count(a3, c("/JJ", "/JJR", "/JJS")))
str_count(a3, c("/JJ", "/JJR", "/JJS"))
essay_tagged <-tagPOS(Train_dat[1:10,3], language="en")
adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS")))
adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS"))))
adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS"))))
adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x[1], c("/JJ", "/JJR", "/JJS"))))
essay_tagged <- as.data.frame( tagPOS(Train_dat[1:10,3], language="en"))
adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS"))))
fix(adj_count)
adj_count[1]
adj_count[2]
essay_tagged <- as.data.frame(tagPOS(Train_dat[,3], language="en"))
Train_dat$adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS"))))
Train_dat$adv_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/RB", "/RBR", "/RBS"))))
Train_dat$to_count <- apply(essay_tagged, 1, function(x) str_count(x, "/TO"))
Train_dat$dt_count <- apply(essay_tagged, 1, function(x) str_count(x, "/DT"))
Train_dat$in_count <- apply(essay_tagged, 1, function(x) str_count(x, "/IN"))
View(Train_dat)
names(Train_dat)
mod2 <-randomForest(factor(grade)~set+word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=Train_dat,
importance=TRUE,proximity=TRUE)
Train_dat[which(!complete.cases(Train_dat)),]
Train_dat2 <- na.omit(Train_dat)
mod2 <-randomForest(factor(grade)~set+word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=Train_dat,
importance=TRUE,proximity=TRUE)
mod2 <-randomForest(factor(grade)~set+word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=Train_dat2,
importance=TRUE,proximity=TRUE)
mod2
Train_dat$avg_word_length <- Train_dat$total_char/Train_dat$word_count
Train_dat2 <- na.omit(Train_dat)
mod2 <-randomForest(factor(grade)~set+word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=Train_dat2,
importance=TRUE,proximity=TRUE)
mod2
save.image("~/GitHub/Kaggle_Essay_score/work.RData")
load("~/GitHub/Kaggle_Essay_score/.RData")
Train_dat2[,2] ==1
dat1 <- Train_dat2[ , Train_dat2[,2] ==1]
dat1 <- Train_dat2[Train_dat2[,2]==1,]
unique(Train_dat2[,2])
dat1 <- Train_dat2[Train_dat2[,2]==2,]
dat1 <- Train_dat2[Train_dat2[,2]==3,]
dat1 <- Train_dat2[Train_dat2[,2]==4,]
dat1 <- Train_dat2[Train_dat2[,2]==5,]
dat1 <- Train_dat2[Train_dat2[,2]==1,]
dat2 <- Train_dat2[Train_dat2[,2]==2,]
dat3 <- Train_dat2[Train_dat2[,2]==3,]
dat4 <- Train_dat2[Train_dat2[,2]==4,]
dat5 <- Train_dat2[Train_dat2[,2]==5,]
mod1 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat1,
importance=TRUE,proximity=TRUE)
mod2 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat2,
importance=TRUE,proximity=TRUE)
mod3 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat3,
importance=TRUE,proximity=TRUE)
mod4 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat4
importance=TRUE,proximity=TRUE)
mod5 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat5,
importance=TRUE,proximity=TRUE)
require(randomForest)
mod1 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat1,
importance=TRUE,proximity=TRUE)
mod2 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat2,
importance=TRUE,proximity=TRUE)
mod3 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat3,
importance=TRUE,proximity=TRUE)
mod4 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat4
importance=TRUE,proximity=TRUE)
mod5 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat5,
importance=TRUE,proximity=TRUE)
mod1
mod2
mod3
mod4
mod5
mod4
mod4 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat4
importance=TRUE,proximity=TRUE)
mod4 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat4,
importance=TRUE,proximity=TRUE)
mod4
mod1
mod2
mod3
mod4
mod5
require(gdata)
require(randomForest)
require(adabag)
require(openNLP)
require(tm)
require(Snowball)
require(stringr)
rm(list=ls())
Train_dat <- read.delim("D:/Rlab/W4242/Hw4/Kaggle/train.tsv", header=T, sep="\t")
head(Train_dat)
Train_dat[,3] <- as.character(Train_dat[,3])
##### plain txt for col 7
Train_dat[,7] <- apply(Train_dat, 1, function(x) gsub("([[:punct:]]+)","",x[3]))
names(Train_dat)[7] <- "Essay_Plain_Text"
View(Train_dat)
##### Calculate Number of word in essay
Train_dat[,8] <- apply(Train_dat, 1, function(x){
mm <- x[3]
if (regexpr("[[:punct:]]+", mm) == 1)
{
mm <- sub("([[:punct:]]+)","",mm)
}
if (regexpr("[[:space:]]+", mm) == 1)
{
mm <- sub("([[:space:]]+)","",mm)
}
nn <- length(gregexpr("\\W+", mm)[[1]])
return (nn)
#return(mm)
})
names(Train_dat)[8] <- c("word_count")
class(Train_dat[,2])
Train_dat[,2] <- factor(Train_dat[,2])
names(Train_dat)
##### Calculate Number of sentences in essay
sentence_count <- apply(Train_dat, 1, function(x) length(sentDetect(x[3], language = "en")))
Train_dat <- cbind(Train_dat,sentence_count)
##### Calculate avg sentence length
Train_dat$avg_stnce_lgth <- Train_dat[,8]/Train_dat[,9]
Train_dat$word_count2 <- apply(Train_dat, 1, function(x) length(tokenize(x[7], language = "en")))
Train_dat$total_char <- apply(Train_dat, 1, function(x) nchar(gsub("([[:space:]]+)","",x[7]), type="chars", allowNA=F))
Train_dat$avg_word_length <- Train_dat$total_char/Train_dat$word_count
Train_dat$diff <- Train_dat$word_count-Train_dat$word_count2
essay_tagged <- as.data.frame(tagPOS(Train_dat[,3], language="en"))
Train_dat$adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS"))))
Train_dat$adv_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/RB", "/RBR", "/RBS"))))
Train_dat$to_count <- apply(essay_tagged, 1, function(x) str_count(x, "/TO"))
Train_dat$dt_count <- apply(essay_tagged, 1, function(x) str_count(x, "/DT"))
Train_dat$in_count <- apply(essay_tagged, 1, function(x) str_count(x, "/IN"))
Train_dat2 <- na.omit(Train_dat)
dat1 <- Train_dat2[Train_dat2[,2]==1,]
dat2 <- Train_dat2[Train_dat2[,2]==2,]
dat3 <- Train_dat2[Train_dat2[,2]==3,]
dat4 <- Train_dat2[Train_dat2[,2]==4,]
dat5 <- Train_dat2[Train_dat2[,2]==5,]
mod1 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat1,
importance=TRUE,proximity=TRUE)
mod2 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat2,
importance=TRUE,proximity=TRUE)
mod3 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat3,
importance=TRUE,proximity=TRUE)
mod4 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat4,
importance=TRUE,proximity=TRUE)
mod5 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat5,
importance=TRUE,proximity=TRUE)
mod1
mod2
mod3
mod4
mod5
names(Train_dat)
mod6 <-randomForest(factor(grade)~set + word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=Train_dat2,
importance=TRUE,proximity=TRUE)
mod6
Test_dat <- read.delim("D:/Rlab/W4242/Hw4/Kaggle/test.tsv", header=T, sep="\t")
View(Test_dat)
Train_dat[,4] <- apply(Train_dat, 1, function(x) gsub("([[:punct:]]+)","",x[3]))
names(Train_dat)[4] <- "Essay_Plain_Text"
View(Train_dat)
Train_dat[,4] <- apply(Test_dat, 1, function(x) gsub("([[:punct:]]+)","",x[3]))
names(Test_dat)[4] <- "Essay_Plain_Text"
Train_dat[,4] <- apply(Test_dat, 1, function(x) gsub("([[:punct:]]+)","",x[3]))
Test_dat[,4] <- apply(Test_dat, 1, function(x) gsub("([[:punct:]]+)","",x[3]))
names(Test_dat)[4] <- "Essay_Plain_Text"
Test_dat[,4] <- apply(Test_dat, 1, function(x){
mm <- x[3]
if (regexpr("[[:punct:]]+", mm) == 1)
{
mm <- sub("([[:punct:]]+)","",mm)
}
if (regexpr("[[:space:]]+", mm) == 1)
{
mm <- sub("([[:space:]]+)","",mm)
}
nn <- length(gregexpr("\\W+", mm)[[1]])
return (nn)
#return(mm)
Test_dat[,5] <- apply(Test_dat, 1, function(x){
mm <- x[3]
if (regexpr("[[:punct:]]+", mm) == 1)
{
mm <- sub("([[:punct:]]+)","",mm)
}
if (regexpr("[[:space:]]+", mm) == 1)
{
mm <- sub("([[:space:]]+)","",mm)
}
nn <- length(gregexpr("\\W+", mm)[[1]])
return (nn)
#return(mm)
})
Test_dat[,5] <- apply(Test_dat, 1, function(x){
mm <- x[3]
if (regexpr("[[:punct:]]+", mm) == 1)
{
mm <- sub("([[:punct:]]+)","",mm)
}
if (regexpr("[[:space:]]+", mm) == 1)
{
mm <- sub("([[:space:]]+)","",mm)
}
nn <- length(gregexpr("\\W+", mm)[[1]])
return (nn)
#return(mm)
})
Test_dat[,5] <- apply(Test_dat, 1, function(x){
mm <- x[3]
if (regexpr("[[:punct:]]+", mm) == 1)
{
mm <- sub("([[:punct:]]+)","",mm)
}
if (regexpr("[[:space:]]+", mm) == 1)
{
mm <- sub("([[:space:]]+)","",mm)
}
nn <- length(gregexpr("\\W+", mm)[[1]])
return (nn)
#return(mm)
})
View(Test_dat)
View(Test_dat)
View(Test_dat)
View(Test_dat)
View(Train_dat)
require(gdata)
require(randomForest)
require(adabag)
require(openNLP)
require(tm)
require(Snowball)
require(stringr)
load("~/GitHub/Kaggle_Essay_score/.RData")
View(Train_dat)
rm(list=ls())
Test_dat <- read.delim("D:/Rlab/W4242/Hw4/Kaggle/test.tsv", header=T, sep="\t")
Train_dat <- read.delim("D:/Rlab/W4242/Hw4/Kaggle/train.tsv", header=T, sep="\t")
head(Train_dat)
Train_dat[,3] <- as.character(Train_dat[,3])
View(Test_dat)
##### plain txt for col 7
Train_dat[,7] <- apply(Train_dat, 1, function(x) gsub("([[:punct:]]+)","",x[3]))
names(Train_dat)[7] <- "Essay_Plain_Text"
##### Calculate Number of word in essay
Train_dat[,8] <- apply(Train_dat, 1, function(x){
mm <- x[3]
if (regexpr("[[:punct:]]+", mm) == 1)
{
mm <- sub("([[:punct:]]+)","",mm)
}
if (regexpr("[[:space:]]+", mm) == 1)
{
mm <- sub("([[:space:]]+)","",mm)
}
nn <- length(gregexpr("\\W+", mm)[[1]])
return (nn)
#return(mm)
})
names(Train_dat)[8] <- c("word_count")
class(Train_dat[,2])
Train_dat[,2] <- factor(Train_dat[,2])
names(Train_dat)
##### Calculate Number of sentences in essay
sentence_count <- apply(Train_dat, 1, function(x) length(sentDetect(x[3], language = "en")))
Train_dat <- cbind(Train_dat,sentence_count)
##### Calculate avg sentence length
Train_dat$avg_stnce_lgth <- Train_dat[,8]/Train_dat[,9]
##### Calculate Word Count based on plain txt
Train_dat$word_count2 <- apply(Train_dat, 1, function(x) length(tokenize(x[7], language = "en")))
##### Calculate Total chars in essay
Train_dat$total_char <- apply(Train_dat, 1, function(x) nchar(gsub("([[:space:]]+)","",x[7]), type="chars", allowNA=F))
##### avg word length
Train_dat$avg_word_length <- Train_dat$total_char/Train_dat$word_count
Train_dat$diff <- Train_dat$word_count-Train_dat$word_count2
##### adj adv dt to in count
essay_tagged <- as.data.frame(tagPOS(Train_dat[,3], language="en"))
Train_dat$adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS"))))
Train_dat$adv_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/RB", "/RBR", "/RBS"))))
Train_dat$to_count <- apply(essay_tagged, 1, function(x) str_count(x, "/TO"))
Train_dat$dt_count <- apply(essay_tagged, 1, function(x) str_count(x, "/DT"))
Train_dat$in_count <- apply(essay_tagged, 1, function(x) str_count(x, "/IN"))
# Check the distribution of word.count in different respectively
for (i in 1:5)
{
print(summary(subset(Train_dat,set==i)$word_count))
}
# Handeling Missing value
Train_dat[which(!complete.cases(Train_dat)),]
Train_dat2 <- na.omit(Train_dat)
train <- Train_dat2[,c(2,6:7)]
dat1 <- Train_dat2[Train_dat2[,2]==1,]
dat2 <- Train_dat2[Train_dat2[,2]==2,]
dat3 <- Train_dat2[Train_dat2[,2]==3,]
dat4 <- Train_dat2[Train_dat2[,2]==4,]
dat5 <- Train_dat2[Train_dat2[,2]==5,]
Test_dat <- read.delim("D:/Rlab/W4242/Hw4/Kaggle/test.tsv", header=T, sep="\t")
Test_dat[,4] <- apply(Test_dat, 1, function(x) gsub("([[:punct:]]+)","",x[3]))
names(Test_dat)[4] <- "Essay_Plain_Text"
Test_dat[,5] <- apply(Test_dat, 1, function(x){
mm <- x[3]
if (regexpr("[[:punct:]]+", mm) == 1)
{
mm <- sub("([[:punct:]]+)","",mm)
}
if (regexpr("[[:space:]]+", mm) == 1)
{
mm <- sub("([[:space:]]+)","",mm)
}
nn <- length(gregexpr("\\W+", mm)[[1]])
return (nn)
#return(mm)
})
#names(Test_dat)[2] <- "set_no"
names(Test_dat)[5] <- "word_count"
class(Test_dat[,2])
Test_dat[,2] <- factor(Test_dat[,2])
##### Calculate Number of sentences in essay
Test_dat$sentence_count <- apply(Test_dat, 1, function(x) length(sentDetect(x[3], language = "en")))
##### Calculate avg sentence length
Test_dat$avg_stnce_lgth <- Test_dat[,5]/Test_dat[,6]
##### Calculate Word Count based on plain txt
Test_dat$word_count2 <- apply(Test_dat, 1, function(x) length(tokenize(x[4], language = "en")))
##### Calculate Total chars in essay
Test_dat$total_char <- apply(Test_dat, 1, function(x) nchar(gsub("([[:space:]]+)","",x[4]), type="chars", allowNA=F))
##### avg word length
Test_dat$avg_word_length <- Test_dat$total_char/Test_dat$word_count
Test_dat$diff <- Test_dat$word_count-Test_dat$word_count2
##### adj adv dt to in count
essay_tagged <- as.data.frame(tagPOS(Test_dat[,3], language="en"))
Test_dat$adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS"))))
Test_dat$adv_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/RB", "/RBR", "/RBS"))))
Test_dat$to_count <- apply(essay_tagged, 1, function(x) str_count(x, "/TO"))
Test_dat$dt_count <- apply(essay_tagged, 1, function(x) str_count(x, "/DT"))
Test_dat$in_count <- apply(essay_tagged, 1, function(x) str_count(x, "/IN"))
essay_tagged <- as.data.frame(tagPOS(Test_dat[,3], language="en"))
require(openNLP)
View(Test_dat)
essay_tagged2 <- as.data.frame(tagPOS(Test_dat[,3], language="en"))
View(Test_dat)
essay_tagged2 <- as.data.frame(tagPOS(Test_dat[,4], language="en"))
View(essay_tagged)
View(Train_dat)
View(essay_tagged2)
Test_dat$adj_count <- apply(essay_tagged2, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS"))))
Test_dat$adv_count <- apply(essay_tagged2, 1, function(x) sum(str_count(x, c("/RB", "/RBR", "/RBS"))))
Test_dat$to_count <- apply(essay_tagged2, 1, function(x) str_count(x, "/TO"))
Test_dat$dt_count <- apply(essay_tagged2, 1, function(x) str_count(x, "/DT"))
Test_dat$in_count <- apply(essay_tagged2, 1, function(x) str_count(x, "/IN"))
View(Test_dat)
mod1 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat1,
importance=TRUE,proximity=TRUE)
mod2 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat2,
importance=TRUE,proximity=TRUE)
mod3 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat3,
importance=TRUE,proximity=TRUE)
mod4 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat4,
importance=TRUE,proximity=TRUE)
mod5 <-randomForest(factor(grade)~word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=dat5,
importance=TRUE,proximity=TRUE)
mod6 <-randomForest(factor(grade)~set + word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=Train_dat2,
importance=TRUE,proximity=TRUE)
save.image("~/GitHub/Kaggle_Essay_score/.RData")
Test_dat2 <- na.omit(Test_dat)
View(Test_dat)
T_dat1 <- Test_dat[Test_dat[,2]==1,]
T_dat2 <- Test_dat[Test_dat[,2]==2,]
T_dat3 <- Test_dat[Test_dat[,2]==3,]
T_dat4 <- Test_dat[Test_dat[,2]==4,]
T_dat5 <- Test_dat[Test_dat[,2]==5,]
mod1
mod2
mod3
mod4
mod5
Test_pred1<-as.data.frame(predict(mod1,T_dat1))
Test_pred2<-as.data.frame(predict(mod2,T_dat2))
Test_pred3<-as.data.frame(predict(mod3,T_dat3))
Test_pred4<-as.data.frame(predict(mod4,T_dat4))
Test_pred5<-as.data.frame(predict(mod5,T_dat5))
summary(Test_pred1)
Test_pred6<-as.data.frame(predict(mod6,Test_dat))
summary(Test_pred6)
summary(Test_pred1)
summary(Test_pred2)
summary(Test_pred3)
Test_pred1
wt <- rep(1,dim(Test_dat)[1])
Test_pred_all <- rbind(Test_pred1, Test_pred2, Test_pred3, Test_pred4, Test_pred5)
View(Test_pred1)
Test_pred_all <- rbind(Test_pred1, Test_pred2, Test_pred3, Test_pred4, Test_pred5)
names(Test_pred1) <- NULL
names(Test_pred1)
names(Test_pred2)
names(Test_pred1) <- NULL
names(Test_pred2) <- NULL
names(Test_pred3) <- NULL
names(Test_pred4) <- NULL
names(Test_pred5) <- NULL
Test_pred_all <- rbind(Test_pred1, Test_pred2, Test_pred3, Test_pred4, Test_pred5)
Test_pred_all <- rbind(Test_pred1, Test_pred2, Test_pred3, Test_pred4, Test_pred5)
names(Test_pred1) <- "pred"
names(Test_pred1)
names(Test_pred1) <- "pred"
names(Test_pred2) <- "pred"
names(Test_pred3) <- "pred"
names(Test_pred4) <- "pred"
names(Test_pred5) <- "pred"
Test_pred_all <- rbind(Test_pred1, Test_pred2, Test_pred3, Test_pred4, Test_pred5)
a1 <- Test_pred_all - Test_pred6
a1 <- Test_pred_all[,1] - Test_pred6[,1]
a1 <- Test_pred_all[,1] == Test_pred6[,1]
a1
Test_output <- cbind(Test_dat[,1:2],wt,Test_pred)
Test_output <- cbind(Test_dat[,1:2],wt,Test_pred_all)
names(Test_output)
names(Test_output)[3:4] <- c("weight", "grade")
write.csv(Test_output,"D:/Rlab/W4242/Hw4/output.csv")
a2 <- as.numeric(a1)
a2
sum(a2)
Test_output <- cbind(Test_dat[,1:2],wt,Test_pred6)
names(Test_output)[3:4] <- c("weight", "grade")
write.csv(Test_output,"D:/Rlab/W4242/Hw4/output.csv")
