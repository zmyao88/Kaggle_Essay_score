require(gdata)
require(randomForest)
require(adabag)
Train_dat <- read.delim("D:/Rlab/W4242/Hw4/Kaggle/train.tsv", header=T, sep="\t")
head(Train_dat)
Train_dat[,3] <- as.character(Train_dat[,3])
Train_dat[,7] <- apply(Train_dat, 1, function(x){
mm <- x[3]
if (regexpr("[[:punct:]]+", mm) == 1)
{
mm <- sub("([[:punct:]]+)","",mm)
}
if (regexpr("[[:space:]]+", mm) == 1)
{
mm <- sub("([[:space:]]+)","",mm)
}
nn <- length(gregexpr("\\W+", mm)[[1]])
return (nn)
#return(mm)
})
names(Train_dat)[7] <- c("word_count")
class(Train_dat[,2])
Train_dat[,2] <- factor(Train_dat[,2])
names(Train_dat)
# Check the distribution of word.count in different respectively
for (i in 1:5)
{
print(summary(subset(Train_dat,set==i)$word_count))
}
View(Train_dat)
s <- "This is a sentence. This another---but with dash-like structures, and some commas.
Maybe another with question marks? Sure!"
sentDetect(s, language = "en")
install.packages("OpenNLP")
require(OpenNLP)
install.packages("openNLP")
require(openNLP)
s <- "This is a sentence. This another---but with dash-like structures, and some commas.
Maybe another with question marks? Sure!"
sentDetect(s, language = "en")
install.packages("openNLPmodels.en")
s <- "This is a sentence. This another---but with dash-like structures, and some commas.
Maybe another with question marks? Sure!"
sentDetect(s, language = "en")
sts <- sentDetect(s, language = "en")
fix(sts)
sts[1]
class(Train_dat[,2])
Train_dat[,2] <- factor(Train_dat[,2])
names(Train_dat)
View(Train_dat)
sts <- sentDetect(Train_dat[1,3], language = "en")
sts <- sentDetect(Train_dat[,3], language = "en")
fix(sts)
length(sts)
sts <- sentDetect(Train_dat[2,3], language = "en")
length(sts)
Train_dat[,8] <- NA
Train_dat[,8] <- apply(Train_dat, 1, function(x) {
sts_cout<- length(sentDetect(x[3], language = "en"))
return(sts_count)
})
Train_dat[,8] <- apply(Train_dat, 1, function(x) {
sts_count <- length(sentDetect(x[3], language = "en"))
return(sts_count)
})
View(Train_dat)
?ldply
attr_name <- read.delim("C:/Users/Zaiming/Documents/GitHub/Ada_Project/attr_name.txt", header=F, sep="\\")
a1 <- apply(Train_dat, 1, function(x) length(sentDetect(x[3], language = "en"))
a1 <- apply(Train_dat, 1, function(x) length(sentDetect(x[3], language = "en")))
a1 <- apply(Train_dat, 1, function(x) length(sentDetect(x[3], language = "en")))
View(a1)
class(a1)
a2 <- cbind(Train_dat,a1)
View(`a2`)
Train_dat[,8] <- NULL
View(Train_dat)
View(Train_dat)
sentence_count <- apply(Train_dat, 1, function(x) length(sentDetect(x[3], language = "en")))
Train_dat <- cbind(Train_dat,sentence_count)
names(Train_dat)
avg_stnce_lgth <- Train_dat[,7]/Train_dat[,8]
Train_dat$avg_stnce_lgth <- Train_dat[,7]/Train_dat[,8]
names(Train_dat)
View(Train_dat)
?tagPOS
sentence <- "This is a short sentence consisting of some nouns, verbs, and adjectives."
tagPOS(sentence, language = "en")
a1 <- tagPOS(sentence, language = "en")
fix(`a1`)
s <- "This is a sentence."
tokenize(s, language = "en")
a2 <-tagPOS(ss, language="en")
ss <- tokenize(s, language = "en")
a2 <-tagPOS(ss, language="en")
a2
a2 <-tagPOS(Train_dat[1,3], language="en")
a2
View(a2)
library("tm")
require(tm)
install.packages("Snowball")
require(Snowball)
source <- readLines(system.file("words", "porter","voc.txt",
package = "Snowball"))
result <- SnowballStemmer(source)
result
source
target <- readLines(system.file("words", "porter", "output.txt",
package = "Snowball"))
target
result <- SnowballStemmer(s)
result
s <- "This is a sentence sentences."
result <- SnowballStemmer(s)
result
s <- "This is a sentence sentences."
ss <- tokenize(s, language = "en")
s
ss
a1 <- Train_dat[,7]
a1 <- Train_dat[1,7]
a1
a2 <- tokenize(a1, language = "en")
a2
a2 <- tokenize(Train_dat[,3], language = "en")
a2
s <- "This is a sentence sentences."
ss <- tokenize(s, language = "en")
ss
class(ss)
ss[1]
class(ss[1])
length(ss)
length(ss[1])
?nchar
nchar(ss[1], type="chars", allowNA=F)
nchar(ss, type="chars", allowNA=F)
ss <- tokenize(Train_dat[1,3], language = "en")
ss
length(ss)
Train_dat[1,7]
s <- "This is a sentence sentences. ? ! ! "
ss <- tokenize(s, language = "en")
ss
s <- "This is a sentence sentences. ? ! ! "
ss <- tokenize(s, language = "en")
Train_dat[1,7]
length(ss)
nchar(ss, type="chars", allowNA=F)
Train_dat[,10] <- apply(Train_dat, 1, function(x){
mm <- x[3]
if (regexpr("[[:punct:]]+", mm) == 1)
{
mm <- sub("([[:punct:]]+)","",mm)
}
if (regexpr("[[:space:]]+", mm) == 1)
{
mm <- sub("([[:space:]]+)","",mm)
}
nn <- length(gregexpr("\\W+", mm)[[1]])
#return (nn)
return(mm)
})
ss <- tokenize(Train_dat[1,10], language = "en")
ss
Train_dat[1,7]
length(ss)
?regexpr
Train_dat[,10] <- apply(Train_dat, 1, function(x) gsub("([[:punct:]]+)","",x[3]))
View(Train_dat)
ss <- tokenize(Train_dat[1,10], language = "en")
length(ss)
Train_dat[1,10]
View(Train_dat)
Train_dat[,7] <- apply(Train_dat, 1, function(x) gsub("([[:punct:]]+)","",x[3]))
names(Train_dat)
View(Train_dat)
names(Train_dat)[7]
names(Train_dat)[7] <- "Essay_Plain_Text"
Train_dat[,8] <- apply(Train_dat, 1, function(x){
mm <- x[3]
if (regexpr("[[:punct:]]+", mm) == 1)
{
mm <- sub("([[:punct:]]+)","",mm)
}
if (regexpr("[[:space:]]+", mm) == 1)
{
mm <- sub("([[:space:]]+)","",mm)
}
nn <- length(gregexpr("\\W+", mm)[[1]])
return (nn)
#return(mm)
})
names(Train_dat)[8] <- c("word_count")
class(Train_dat[,2])
Train_dat[,2] <- factor(Train_dat[,2])
names(Train_dat)
sentence_count <- apply(Train_dat, 1, function(x) length(sentDetect(x[3], language = "en")))
Train_dat <- cbind(Train_dat,sentence_count)
Train_dat$avg_stnce_lgth <- Train_dat[,8]/Train_dat[,9]
View(Train_dat)
ss <- tokenize(Train_dat[,7], language = "en")
Train_dat$word_count2 <- apply(Train_dat, 1, function(x) tokenize(x[7], language = "en"))
ss <- tokenize(Train_dat[1,7], language="en")
ss
length(ss)
nchar(ss, type="chars", allowNA=F)
a1 <- nchar(ss, type="chars", allowNA=F)
a1
sum(a1)
a1 <- sum(nchar(ss, type="chars", allowNA=F))
a1 <- sum(nchar(ss, type="chars", allowNA=F))
nchar(Train_dat[1,7],type="chars", allowNA=F)
?system.time
system.time(sum(nchar(ss, type="chars", allowNA=F)))
system.time(nchar(Train_dat[1,7],type="chars", allowNA=F))
Train_dat$word_count2 <- apply(Train_dat, 1, function(x) length(tokenize(x[7], language = "en")))
View(Train_dat)
Train_dat$total_char <- apply(Train_dat, 1, function(x) nchar(gsub("([[:space:]]+)","",x[7]), type="chars", allowNA=F)
Train_dat$total_char <- apply(Train_dat, 1, function(x) nchar(gsub("([[:space:]]+)","",x[7]), type="chars", allowNA=F))
Train_dat$total_char <- apply(Train_dat, 1, function(x) nchar(gsub("([[:space:]]+)","",x[7]), type="chars", allowNA=F))
View(Train_dat)
Train_dat$avg_word_length <- Train_dat$total_char/Train_dat$word_count2
Train_dat$diff <- Train_dat$word_count-Train_dat$word_count2
Train_dat$diff
View(Train_dat)
a3 <-tagPOS(Train_dat[1,3], language="en")
a3
str_count(a3, c("/JJ", "/JJR", "/JJS"))
require(stringr)
str_count(a3, c("/JJ", "/JJR", "/JJS"))
sum(str_count(a3, c("/JJ", "/JJR", "/JJS")))
adv_count <- sum(str_count(a3, c("/RB", "/RBR", "/RBS")))
adv_count
str_count(a3, c("/RB", "/RBR", "/RBS"))
to_count <- str_count(a3, "/TO")))
to_count <- str_count(a3, "/TO")
to_count
dt_count <- str_count(a3, "/DT")
dt_count
in_count <- str_count(a3, "/IN")
in_count
a3 <-tagPOS(Train_dat[,3], language="en")
a3 <-tagPOS(Train_dat[1:2,3], language="en")
a3
str_count(a3, c("/JJ", "/JJR", "/JJS"))
essay_tagged <-tagPOS(Train_dat[1:10,3], language="en")
adj_count <- sum(str_count(a3, c("/JJ", "/JJR", "/JJS")))
str_count(a3, c("/JJ", "/JJR", "/JJS"))
essay_tagged <-tagPOS(Train_dat[1:10,3], language="en")
adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS")))
adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS"))))
adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS"))))
adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x[1], c("/JJ", "/JJR", "/JJS"))))
essay_tagged <- as.data.frame( tagPOS(Train_dat[1:10,3], language="en"))
adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS"))))
fix(adj_count)
adj_count[1]
adj_count[2]
essay_tagged <- as.data.frame(tagPOS(Train_dat[,3], language="en"))
Train_dat$adj_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/JJ", "/JJR", "/JJS"))))
Train_dat$adv_count <- apply(essay_tagged, 1, function(x) sum(str_count(x, c("/RB", "/RBR", "/RBS"))))
Train_dat$to_count <- apply(essay_tagged, 1, function(x) str_count(x, "/TO"))
Train_dat$dt_count <- apply(essay_tagged, 1, function(x) str_count(x, "/DT"))
Train_dat$in_count <- apply(essay_tagged, 1, function(x) str_count(x, "/IN"))
View(Train_dat)
names(Train_dat)
mod2 <-randomForest(factor(grade)~set+word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=Train_dat,
importance=TRUE,proximity=TRUE)
Train_dat[which(!complete.cases(Train_dat)),]
Train_dat2 <- na.omit(Train_dat)
mod2 <-randomForest(factor(grade)~set+word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=Train_dat,
importance=TRUE,proximity=TRUE)
mod2 <-randomForest(factor(grade)~set+word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=Train_dat2,
importance=TRUE,proximity=TRUE)
mod2
Train_dat$avg_word_length <- Train_dat$total_char/Train_dat$word_count
Train_dat2 <- na.omit(Train_dat)
mod2 <-randomForest(factor(grade)~set+word_count2+avg_stnce_lgth+avg_word_length+sentence_count+adj_count+adv_count+to_count+dt_count+in_count, data=Train_dat2,
importance=TRUE,proximity=TRUE)
mod2
save.image("~/GitHub/Kaggle_Essay_score/work.RData")
